{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYEpxpSRnq8x"
   },
   "source": [
    "## Preprocesamiento de Datos\n",
    "\n",
    "“El Preprocesamiento de Datos” / “La Preparación de\n",
    "Datos” engloba a todas aquellas técnicas de análisis de\n",
    "datos que permite mejorar la calidad de un conjunto de\n",
    "datos de modo que las técnicas de extracción de\n",
    "conocimiento/minería de datos puedan obtener mayor y\n",
    "mejor información (mejor porcentaje de clasificación,\n",
    "reglas con más completitud, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jkc1AAl7nq8y"
   },
   "source": [
    "### Importando las bibliotecas básicas\n",
    "\n",
    "El primer paso en todo programa Python de Machine Learning es el de importar las bibliotecas básicas imprescinibles para hacer nuestro trabajo.\n",
    "\n",
    "Éstas son: pandas, numpy y matplotlib.pyplot. La sentencia Python para importarlas es import (al escribir esta sentencia el código debe quedar de color verde). \n",
    "\n",
    "Para ahorrarnos escribir letras al tipear (los programadores somos muuuuuy vagos) les ponemos un alias a las tres bibliotecas.\n",
    "\n",
    "La sentencia Python para hacer eso es as que también se debe poner verde (y no de envidia). Los  alias fecuentemente usados son plt, pd y np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NY2h7Oehnq80"
   },
   "outputs": [],
   "source": [
    "# Importar las bibliotecas básicas de trabajo\n",
    "# pandas (pd), numpy (np) y matplotlib.pyplot (plt)\n",
    "\n",
    "# Comenzar código aquí (tres líneas)\n",
    "import pandas as pd                     # importamos la biblotecas pandas (pd) - Manejo de Datasets\n",
    "                     # importamos la biblioteca numpy (np)  - Vectores y matrices\n",
    "                     # importamos la biblioteca matplotlib.pyplot - Gráficos \n",
    "# Fin del código  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tH1UitMNnq85"
   },
   "source": [
    "## Importando el dataset\n",
    "\n",
    "El primer paso necesario para comenzar a preprocesar los datos es traernos el dataset con el que vamos a trabajar a memoria. Eso lo hacemos utilizando la biblioteca pandas. El método que tenemos que usar es read_csv. Como argumentos del método, debemos poner, entre comillas, el nombre de nuestro dataset incluyendo la ruta correspondiente. \n",
    "<br><i>(pd.read_csv (\"../../datasets/Data.csv\"))<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w95W3XaVnq87"
   },
   "outputs": [],
   "source": [
    "# Comenzar código aquí (una línea)\n",
    "datos = pd.read_csv(\"datasets/Data.csv\")                     \n",
    "# Fin del código  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obDFk7UZnq8_"
   },
   "source": [
    "### Resultado esperado\n",
    "\n",
    "<img src=\"imagenes/dataset.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "409d1x6Tnq9B"
   },
   "source": [
    "### Almacenamiento de los datos en una variable\n",
    "\n",
    "En el paso anterior, leímos el dataset. Para poder trabajar con el mismo, debemos alojarlo en memoria. Para eso, debemos definir una variable en la que almacenar el objeto DataFrame resultante de la lectura de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V6JujIKEnq9G"
   },
   "source": [
    "### Mostrando los datos\n",
    "\n",
    "Para mostrar los datos almacenados en la variable datos, podemos hacerlo simplemente tipeando datos. Sin embargo, si el dataset es muy grande, esto no es práctico. Solo deseamos obtener una muestra de los datos para chequear que el dateset se ha leído correctamente. Para hacer esto, debemos usar el método head de pandas.<br>\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoJVTTY6nq9I",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Country   Age   Salary Purchased\n0   France  44.0  72000.0        No\n1    Spain  27.0  48000.0       Yes\n2  Germany  30.0  54000.0        No\n3    Spain  38.0  61000.0        No\n4  Germany  40.0      NaN       Yes",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Age</th>\n      <th>Salary</th>\n      <th>Purchased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>France</td>\n      <td>44.0</td>\n      <td>72000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Spain</td>\n      <td>27.0</td>\n      <td>48000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Germany</td>\n      <td>30.0</td>\n      <td>54000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Spain</td>\n      <td>38.0</td>\n      <td>61000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Germany</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Comenzar código aquí (una línea)\n",
    "\n",
    "datos.head()\n",
    "# Fin del código  \n",
    "\n",
    "## DESAFÍO: mostrar los últimos tres datos del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4i89CGOnq9M"
   },
   "source": [
    "### Resultado esperado\n",
    "\n",
    "<img src=\"imagenes/head.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THC5Ftqknq9O"
   },
   "source": [
    "### Separando en nuestro DataFrame las variables independientes (X) y la dependiente (y)\n",
    "\n",
    "Ahora, tomamos nuestro DataFrame, almacenado en la variable datos, y lo separamos en dos subdataframes. Uno, conteniendo las variables independientes, que son todas las columnas menos la última y otro, conteniendo la variable dependiente, que es la columna número 3. \n",
    "\n",
    "#### Primer paso: dividiendo el dataframe en subdataframes\n",
    "\n",
    "Para seccionar nuestro dataframe debemos usar el método iloc. Entre corchetes, indicamos primero el número de filas que vamos a seleccionar (en este caso, con :, indicamos que seleccionaremos todas las filas) y luego, todas las columnas (en este caso, con ;-1, indicamos que seleccionaremos todas las columnnas menos una). Esto que acabamos de hacer se aplica a la variable independiente (X). Para la y, tomaremos también todas las filas y nos quedaremos solo con la columna 3.     \n",
    "\n",
    "#### Segundo paso: transformando los dataframes en arrays de numpy\n",
    "\n",
    "Para operar con los datos, debemos transformarlos en arrays de numpy. Esto lo hacemos con el método values.\n",
    "\n",
    "#### Tercer paso: mostramos X e y\n",
    "\n",
    "Esto simplemente lo hacemos tipeando los nombres de las variables <br>\n",
    "\n",
    "X=datos.iloc[:,:-1].values <br>\n",
    "y=datos.iloc[:,3].values   <br>\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZY5ovBjNnq9P"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([['France', 44.0, 72000.0],\n        ['Spain', 27.0, 48000.0],\n        ['Germany', 30.0, 54000.0],\n        ['Spain', 38.0, 61000.0],\n        ['Germany', 40.0, nan],\n        ['France', 35.0, 58000.0],\n        ['Spain', nan, 52000.0],\n        ['France', 48.0, 79000.0],\n        ['Germany', 50.0, 83000.0],\n        ['France', 37.0, 67000.0]], dtype=object),\n array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n       dtype=object))"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Comenzar código aquí (tres líneas)\n",
    "X=datos.iloc[:,:-1].values                  # separamos las variables independientes (X)\n",
    "y=datos.iloc[:,3].values                            # separamos la variable dependiente (y) \n",
    "X,y                            # mostramos X e y \n",
    "# Fin del código  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Na-pF0MLnq9W"
   },
   "source": [
    "### Resultado esperado\n",
    "\n",
    "<img src=\"imagenes/Xy.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBOZXnuSnq9X"
   },
   "source": [
    "### Tratamiento de los valores faltantes\n",
    "\n",
    "¿Qué hacer cuando tenemos valores faltantes?\n",
    "\n",
    "\n",
    "Una situación a la que se enfrenta frecuentemente cualquier científico de datos es el tratamiento de los valores perdidos. Los valores faltantes son aquellos que para una variable determinada no constan en algunas filas o patrones. El motivo por el cual se produce esto puede ir desde fallos en los instrumentos de medida hasta sujetos que no asisten a la entrevista o no contestan a determinadas preguntas.\n",
    "\n",
    "Los 3 motivos principales por los que se suelen tratar los valores perdidos son: pueden introducir un sesgo considerable (una diferencia notable entre los datos observados y los no observados), hacen el análisis y el manejo de los datos más complicado y la pérdida de información que éstos producen.\n",
    "\n",
    "No es tan importante la cantidad de valores faltantes como el patrón que éstos siguen. Puesto que si su distribución no fuese aleatoria a lo largo de todo el conjunto de datos la representatividad de la muestra sobre la que estaríamos trabajando se vería seriamente mermada. Por lo tanto, en función de la aleatoriedad de los valores perdidos se suele establecer la siguiente clasificación:\n",
    "\n",
    "Missing At Random (MAR): ocurre cuando la ausencia de los datos podría depender de los valores observados.\n",
    "Missing Not At Random (MNAR): si el ser un dato faltante depende del valor de los datos no observados.\n",
    "Missing Completely At Random (MCAR): si el evento de que cierto valor sea faltante es independiente de las variables observadas y no observadas, y ocurre de forma completamente aleatoria. Se trata de un caso especial de MAR.\n",
    "La principal ventaja de que los valores perdidos sean de tipo MCAR es que los datos no están sesgados. Ocurre de igual forma con los de tipo MAR.\n",
    "\n",
    "Hay que tener especial cuidado con los valores perdidos de tipo MNAR, ya que los datos observados están sesgados. Destacar que este tipo de valores faltantes no se puede ignorar y debe ser tratado junto al experto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fYb6ydnFnq9Z"
   },
   "source": [
    "### Técnicas para el tratamiento de valores faltantes\n",
    "\n",
    "Existen multitud de procedimientos para aplicar cuando tenemos valores perdidos. Aunque básicamente existen dos aproximaciones posibles:\n",
    "\n",
    "Eliminar muestras o variables que tienen datos faltantes.\n",
    "Imputar los valores perdidos, es decir, sustituirlos por estimaciones.\n",
    "\n",
    "Más info: https://conocemachinelearning.wordpress.com/2017/06/30/valoresfaltantes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGBEJZ2unq9c"
   },
   "source": [
    "### Tratamiento de valores faltantes con sklearn\n",
    "\n",
    "1) Del paquete sklearn.preprocessing importamos la clase Imputer<br>\n",
    "2) Instanciamos un objeto imputer invocando al constructor de la clase\n",
    "   Imputer.<br>\n",
    "   Parámetros que le pasamos al constructor<br>\n",
    "   missing_values = 'NaN'  trata los valores 'NaN' (Not a Number)<br>\n",
    "   strategy = 'mean' reemplaza los valores 'NaN' por el promedio<br>\n",
    "   axis=0 itera a lo largo de todas las filas (verticalmente)<br>\n",
    "3) Una vez instanciado el objeto imputer de la clase Imputer, invocamos a su método fit<br>\n",
    "   Como parámetros del método fit pasamos la las columnas 1 y 2 matriz X \n",
    "   (son las 2 columnas que tienen los valores 'NaN')<br>\n",
    "4) Invocamos al método transform de imputer y le pasamos los mismos parámetros que en el punto 3)<br>\n",
    "   Asignamos el resultado al mismo argumento que pasamos como parámetro.<br>\n",
    "5) Mostramos la matriz X transformada.<br>\n",
    "   \n",
    "from sklearn.preprocessing import Imputer<br>\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean',axis=0)<br>\n",
    "imputer.fit(X[:,1:3])<br>\n",
    "X[:,1:3]=imputer.transform(X[:,1:3])<br>\n",
    "X<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJ0X2TTanq9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comenzar código aquí (cinco líneas)\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy ='mean',axis=0)\n",
    "imputer.fit(X[:,1:3])\n",
    "X[:,1:3]=imputer.transform(X[:,1:3])\n",
    "X\n",
    "\n",
    "\n",
    "# Fin del código  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5SNCch-nq9n"
   },
   "source": [
    "### Resultado esperado\n",
    "\n",
    "<img src=\"imagenes/Nan.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ciKzXnxwnq9p"
   },
   "source": [
    "## Valores categóricos\n",
    "\n",
    "<img src=\"imagenes/categorical_data.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sL022HZgnq9p"
   },
   "source": [
    "## Valores categóricos\n",
    "\n",
    "Introducción\n",
    "Cuando trabajamos con estadísticas, es importante reconocer los diferentes tipos de datos: numéricos (discretos y continuos), categóricos y ordinales. Los datos no son más que observaciones del mundo en que vivimos, por tanto, los mismos pueden venir en diferentes formas, no solo numérica. Por ejemplo, si le preguntáramos a nuestros amigos ¿cuántas mascotas tienen? nos podrían responder: 0, 1, 2, 4, 3, 8; esta información por sí misma puede ser útil, pero para nuestro análisis de mascotas, nos podría servir también otro tipo de información, como por ejemplo el género de cada uno de nuestros amigos; de esta forma obtendríamos la siguiente información: hombre, mujer, mujer, mujer, hombre, mujer. Como vemos, podemos incluir a los datos dentro de tres categorías fundamentales: datos cuantitativos o numéricos, datos cualitativos o categóricos y datos ordinales.\n",
    "\n",
    "Datos cuantitativos\n",
    "Los datos cuantitativos son representados por números; estos números van a ser significativos si representan la medida o la cantidad observada de cierta característica. Dentro de esta categoría podemos encontrar por ejemplo: cantidades de dólares, cuentas, tamaños, número de empleados, y kilómetros por hora. Con los datos cuantitativos, se puede hacer todo tipo de tareas de procesamiento de datos numéricos, tales como sumarlos, calcular promedios, o medir su variabilidad. Asimismo, vamos a poder dividir a los datos cuantitativos en discretos y continuos, dependiendo de los valores potencialmente observables.\n",
    "\n",
    "Los datos discretos solo van a poder asumir un valor de una lista de números específicos. Representan ítems que pueden ser contados; todos sus posibles valores pueden ser listados. Suele ser relativamente fácil trabajar con este tipo de dato.\n",
    "\n",
    "Los datos continuos representan mediciones; sus posibles valores no pueden ser contados y sólo pueden ser descritos usando intervalos en la recta de los números reales. Por ejemplo, la cantidad de kilómetros recorridos no puede ser medida con exactitud, puede ser que hayamos recorrido 1.7 km o 1.6987 km; en cualquier medida que tomemos del mundo real, siempre pueden haber pequeñas o grandes variaciones. Generalmente, los datos continuos se suelen redondear a un número fijo de decimales para facilitar su manipulación.\n",
    "\n",
    "Datos cualitativos\n",
    "Si los datos nos dicen en cual de determinadas categorías no numéricas nuestros ítems van a caer, entonces estamos hablando de datos cualitativos o categóricos; ya que los mismos van a representar determinada cualidad que los ítems poseen. Dentro de esta categoría vamos a encontrar datos como: el sexo de una persona, el estado civil, la ciudad natal, o los tipos de películas que le gustan. Los datos categóricos pueden tomar valores numéricos (por ejemplo, \"1\" para indicar \"masculino\" y \"2\" para indicar \"femenino\"), pero esos números no tienen un sentido matemático.\n",
    "\n",
    "Datos ordinales\n",
    "Una categoría intermedia entre los dos tipos de datos anteriores, son los datos ordinales. En este tipo de datos, va a existir un orden significativo, vamos a poder clasificar un primero, segundo, tercero, etc. es decir, que podemos establecer un ranking para estos datos, el cual posiblemente luego tenga un rol importante en la etapa de análisis. Los datos se dividen en categorías, pero los números colocados en cada categoría tienen un significado. Por ejemplo, la calificación de un restaurante en una escala de 0 (bajo) a 5 (más alta) estrellas representa datos ordinales. Los datos ordinales son a menudo tratados como datos categóricos, en el sentido que se suelen agrupar y ordenar. Sin embargo, a diferencia de los datos categóricos, los números sí tienen un significado matemático.\n",
    "\n",
    "https://relopezbriega.github.io/blog/2016/02/29/analisis-de-datos-categoricos-con-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTlhLAKonq9r"
   },
   "source": [
    "## Análisis de datos categóricos con Python\n",
    "\n",
    "Puesto que las variables cualitativas normalmente recogen aspectos de la presencia o no de\n",
    "determinado atributo (ser hombre o mujer, tener estudios universitarios o no tenerlos, etc.…) se\n",
    "utilizan variables construidas artificialmente, llamadas también ficticias o dummy, que\n",
    "generalmente toman dos valores, 1 ó 0, según se dé o no cierta cualidad o atributo.\n",
    "Habitualmente a la variable ficticia se le asigna el valor 1 en presencia de la cualidad y 0 en\n",
    "caso contrario. Las variables que toman valores 1 y 0, también reciben el nombre de variables\n",
    "dicotómicas o binarias. \n",
    "\n",
    "### Paso 1 codificar los países con LabelEncoder\n",
    "\n",
    "1) Del paquete sklearn.preprocessing importar la clase LabelEncoder  <br>\n",
    "2) Crear una variable labelencoder_X del tipo LabelEncoder <br>\n",
    "3) Aplicar el método fit a la columna de la matriz correspondiente <br>\n",
    "4) Aplicar el método transform a la columna de la matriz correspondiente <br>\n",
    "5) Mostrar los datos transformados <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GweRh8Sinq9t"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 44.0, 72000.0],\n       [2, 27.0, 48000.0],\n       [1, 30.0, 54000.0],\n       [2, 38.0, 61000.0],\n       [1, 40.0, nan],\n       [0, 35.0, 58000.0],\n       [2, nan, 52000.0],\n       [0, 48.0, 79000.0],\n       [1, 50.0, 83000.0],\n       [0, 37.0, 67000.0]], dtype=object)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Comenzar código aquí (cuatro líneas)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X=LabelEncoder()\n",
    "labelencoder_X.fit(X[:,0])\n",
    "X[:,0]=labelencoder_X.transform(X[:,0])\n",
    "X\n",
    "\n",
    "\n",
    "# Fin del código  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9qdc7cWnq9x"
   },
   "source": [
    "### Resultado esperado\n",
    "\n",
    "<img src=\"imagenes/LabelEncoder.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BkFsS9WDnq9y"
   },
   "source": [
    "## Uso de la clase OneHotEncoder para crear variables dummy\n",
    "\n",
    "1) Del paquete sklearn.preprocessing importar la clase OneHotEncoder <br>\n",
    "2) Crear la variable onehotencoder del tipo OneHotEncoder <br>\n",
    "   Parámetro a pasar en el constructor: categorical_features = [0] - la columna a transformar <br>\n",
    "3) Al objeto onehotencoder aplicarle el método fit_t transform <br>\n",
    "   Parámetro a pasar en el método: la matriz X <br>\n",
    "   Aplicar el método toarray para transformarlo en un array de numpy <br>\n",
    "4) Mostrar los datos transformados <br>\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder <br>\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])<br>\n",
    "X=onehotencoder.fit_transform(X).toarray()<br>\n",
    "X<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KxOLHsEInq9z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.40000000e+01, 7.20000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        2.70000000e+01, 4.80000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        3.00000000e+01, 5.40000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.80000000e+01, 6.10000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        4.00000000e+01, 6.37777778e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.50000000e+01, 5.80000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.87777778e+01, 5.20000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.80000000e+01, 7.90000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        5.00000000e+01, 8.30000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.70000000e+01, 6.70000000e+04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comenzar código aquí (cuatro líneas)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder=OneHotEncoder(categorical_features = [0])\n",
    "X=encoder.fit_transform(X).toarray()\n",
    "X\n",
    "\n",
    "\n",
    "# Fin del código  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjZyY2sPnq94"
   },
   "source": [
    "### Resultado esperado\n",
    "\n",
    "<img src=\"imagenes/OneHotEncoderX.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xlH7y2cAnq94"
   },
   "source": [
    "## Tratamiento de los datos categóricos - Variable independiente (y)\n",
    "\n",
    "1) Crear una variable labelencoder_y, instancia de la clase LabelEncoder\n",
    "2) Aplicación del método fit_transform - argumento: y\n",
    "3) Mostrar los datos transformados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bk8qmTJnq96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comenzar código aquí (tres líneas)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y=LabelEncoder()\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "y\n",
    "\n",
    "# Fin del código "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgnzf55Nnq-A"
   },
   "source": [
    "### Resultado esperado\n",
    "\n",
    "<img src=\"imagenes/OneHotEncodery.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEhTrA7lnq-C"
   },
   "source": [
    "## Conjuntos de entrenamiento y testing\n",
    "\n",
    "\n",
    "<img src=\"imagenes/PartitionTwoSets.svg\">\n",
    "\n",
    "1) importar train_test_split del paquete sklearn.cross_validation<br>\n",
    "2) dividir X e y en train y test usando el método train_test_split\n",
    "   Parámetros a aplicar: X, y, test_size = 0.2, random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3CHuJnJnq-D",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comenzar código aquí (dos líneas)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "# Fin del código "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2i-PLLynq-J"
   },
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Dado que los datos de edad y salario mantienen una escala diferente y en las ecuaciones de la regresión o de algún otro método de clasificación y/o predicción, dada la distancia euclidiana entre dos puntos, el valor del salario podría hacer que la edad deje de ser representativa o importante para el análisis, lo mas conveniente es hacer una transformación de escalas, ya sea una estandarización o una normalización de los datos.\n",
    "\n",
    "<img src=\"imagenes/Normalizacion.png\">\n",
    "\n",
    "1) Importar la clase StandardScaler del paquete sklearn.preprocessing <br>\n",
    "2) Crear una instancia de la clase StandardScaler <br>\n",
    "3) Aplicar el método fit_transform con parámetro X_train <br>\n",
    "4) Aplicar el método transform con parámetro X_test <br>\n",
    "5) Mostrar los datos transformados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5YyZoOZnq-L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.        ,  2.64575131, -0.77459667, -1.45882927,\n",
       "        -0.90166297],\n",
       "       [ 1.        , -1.        ,  2.64575131, -0.77459667,  1.98496442,\n",
       "         2.13981082]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comenzar código aquí (cinco líneas)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "X_train=sc_X.fit_transform(X_train)\n",
    "X_test =sc_X.transform(X_test)\n",
    "X_train\n",
    "X_test\n",
    "# Fin del código  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "c11 labs ML Fundamentos PreprocesamientodeDatos.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('posgrado': conda)",
   "language": "python",
   "name": "python37764bitposgradoconda3fc346c30d4442f5aafcbd2979f1dc82"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}